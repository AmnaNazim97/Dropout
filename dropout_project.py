# -*- coding: utf-8 -*-
"""Dropout_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oWVsVA6JzFpiIcX2efFODxLpq0nhn9rL
"""

import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.wrappers.scikit_learn import KerasClassifier
from keras.constraints import max_norm
from keras.optimizers import SGD
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

seed=7
np.random.seed(seed)

import io
from google.colab import files
uploaded = files.upload()
df = pd.read_csv(io.StringIO(uploaded['sonar.csv'].decode('utf-8')))
df

dataset= df.values
x = dataset[:, 0:60].astype(float)
y= dataset[:, 60]
le= LabelEncoder()
le.fit(y)
y_encode= le.transform(y)

#Create Baseline
def baseline_model():
  model= Sequential()
  model.add(Dense(60 , input_dim= 60 , kernel_initializer='normal' , activation='relu'))
  model.add(Dense(30, kernel_initializer='normal', activation='relu'))
  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))
	# Compile model
  sgd = SGD(lr=0.01, momentum=0.8, decay=0.0, nesterov=False)
  model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])
  return model

np.random.seed(seed)
estimators=[]
estimators.append(('standarize' , StandardScaler()))
estimators.append(('mlp' , KerasClassifier(build_fn= baseline_model , epochs=300 , batch_size=16 , verbose=0)))
pipeline= Pipeline(estimators)
kfold= StratifiedKFold(n_splits=10 , shuffle=True , random_state=seed)
results= cross_val_score(pipeline , x ,y_encode , cv= kfold)
print("Baseline: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))

#model using Dropout
def dropout_model():
  model = Sequential()
  model.add(Dense(60 , input_dim=60,  kernel_initializer='normal', activation='relu'))
  model.add(Dropout(0.2))
  model.add(Dense(30, kernel_constraint=max_norm(2.) , kernel_initializer='normal', activation='relu'))
  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))

  sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)
  model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])
  return model

np.random.seed(seed)
estimators = []
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp', KerasClassifier(build_fn=dropout_model, epochs=300, batch_size=16, verbose=0)))
pipeline = Pipeline(estimators)
kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)
results = cross_val_score(pipeline, x, y_encode, cv=kfold)
print("Visible: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))

#Model uses hidden layers
def hidden_model():
  model= Sequential()
  model.add(Dense(60, input_dim=60, kernel_constraint=max_norm(2.) ,  kernel_initializer='normal', activation='relu'))
  model.add(Dropout(0.2))
  model.add(Dense(30, kernel_constraint=max_norm(2.) , kernel_initializer='normal', activation='relu'))
  model.add(Dropout(0.2))
  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))
	# Compile model
  sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)
  model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])
  return model

np.random.seed(seed)
estimators = []
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp', KerasClassifier(build_fn=hidden_model, epochs=300, batch_size=16, verbose=0)))
pipeline = Pipeline(estimators)
kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)
results = cross_val_score(pipeline, x, y_encode, cv=kfold)
print("Hidden: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))

#Create Larger Model
def large_model():
  model = Sequential()
  model.add(Dense(120, input_dim=60, kernel_constraint=max_norm(2.) ,  kernel_initializer='normal', activation='relu'))
  model.add(Dropout(0.2))
  model.add(Dense(60, kernel_constraint=max_norm(2.) , kernel_initializer='normal', activation='relu'))
  model.add(Dropout(0.2))
  model.add(Dense(30, kernel_constraint=max_norm(2.) , kernel_initializer='normal', activation='relu'))
  model.add(Dropout(0.2))
  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))
	# Compile model
  sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)
  model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])
  return model

np.random.seed(seed)
estimators = []
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp', KerasClassifier(build_fn=large_model, epochs=300, batch_size=16, verbose=0)))
pipeline = Pipeline(estimators)
kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)
results = cross_val_score(pipeline, x, y_encode, cv=kfold)
print("Larger: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))

#using constrain
def constrain_model():
	# create model
  model = Sequential()
  model.add(Dense(60, input_dim=60, kernel_constraint=max_norm(5.) ,  kernel_initializer='normal', activation='relu'))
  model.add(Dense(30, kernel_constraint=max_norm(2.) , kernel_initializer='normal', activation='relu'))
  model.add(Dropout(0.2))
  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))
	# Compile model
  sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)
  model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])
  return model

np.random.seed(seed)
estimators = []
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp', KerasClassifier(build_fn=constrain_model, epochs=400, batch_size=16, verbose=0)))
pipeline = Pipeline(estimators)
kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)
results = cross_val_score(pipeline, x, y_encode, cv=kfold)
print("Constraint: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))

